{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7bc164",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a896f",
   "metadata": {},
   "source": [
    "## image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c76eb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([8, 1, 64, 64])\n",
      "Labels: tensor([42, 35, 14, 40, 32, 29, 36, 29])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17d1e2990>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_file):\n",
    "        self.image_dir = image_dir\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Pad((0, 0, 7, 7), fill=0, padding_mode='constant')\n",
    "        ])\n",
    "        self.discrete_labels = pd.cut(self.df['polarizability'], bins=50, labels=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = row['string'] + '.png'\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        image = self.transform(image)\n",
    "        label = self.discrete_labels[idx]\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "# Usage:\n",
    "dataset = CustomDataset('images/', 'input.csv')\n",
    "\n",
    "# Feed it into a dataloader (batch size 8 here just for demo)\n",
    "train_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# View some examples\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Labels:\", y)\n",
    "plt.imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassConditionedUnet(nn.Module):\n",
    "    def __init__(self, num_classes=50, class_emb_size=10):\n",
    "        super().__init__()\n",
    "        self.class_emb = nn.Embedding(num_classes, class_emb_size)\n",
    "        self.model = UNet2DModel(\n",
    "            sample_size=64,\n",
    "            in_channels=1 + class_emb_size,\n",
    "            out_channels=1,\n",
    "            layers_per_block=2,\n",
    "            block_out_channels=(64, 128, 128, 256),\n",
    "            down_block_types=(\"DownBlock2D\", \"AttnDownBlock2D\", \"AttnDownBlock2D\", \"AttnDownBlock2D\"),\n",
    "            up_block_types=(\"AttnUpBlock2D\", \"AttnUpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\"),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t, class_labels):\n",
    "        bs, ch, w, h = x.shape\n",
    "        embed = self.class_emb(class_labels)\n",
    "        class_cond = embed.view(bs, embed.shape[1], 1, 1).expand(bs, embed.shape[1], w, h)\n",
    "        net_input = torch.cat((x, class_cond), 1)\n",
    "        return self.model(net_input, t).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "743acc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule=\"squaredcos_cap_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b885ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48ad304df9b49d9903575a3e907e11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'class_cond' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m noisy_x = noise_scheduler.add_noise(x, noise, timesteps)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Get the model prediction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m pred = \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Note that we pass in the labels y\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Calculate the loss\u001b[39;00m\n\u001b[32m     37\u001b[39m loss = loss_fn(pred, noise)  \u001b[38;5;66;03m# How close is the output to the noise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Apps/PolyGraphPy/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Apps/PolyGraphPy/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mClassConditionedUnet.forward\u001b[39m\u001b[34m(self, x, t, class_labels)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t, class_labels):\n\u001b[32m     16\u001b[39m     bs, ch, w, h = x.shape\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     class_cond = \u001b[38;5;28mself\u001b[39m.class_emb(class_labels).view(bs, \u001b[43mclass_cond\u001b[49m.shape[\u001b[32m1\u001b[39m], \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m).expand(bs, class_cond.shape[\u001b[32m1\u001b[39m], w, h)\n\u001b[32m     18\u001b[39m     net_input = torch.cat((x, class_cond), \u001b[32m1\u001b[39m)\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model(net_input, t).sample\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'class_cond' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Redefining the dataloader to set the batch size higher than the demo of 8\n",
    "train_dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# How many runs through the data should we do?\n",
    "n_epochs = 10\n",
    "\n",
    "# Our network\n",
    "net = ClassConditionedUnet().to(device)\n",
    "\n",
    "# Our loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# The optimizer\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# Keeping a record of the losses for later viewing\n",
    "losses = []\n",
    "\n",
    "# The training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "\n",
    "        # Get some data and prepare the corrupted version\n",
    "        x = x.to(device) * 2 - 1  # Data on the GPU (mapped to (-1, 1))\n",
    "        y = y.to(device)\n",
    "        noise = torch.randn_like(x)\n",
    "        timesteps = torch.randint(0, 999, (x.shape[0],)).long().to(device)\n",
    "        noisy_x = noise_scheduler.add_noise(x, noise, timesteps)\n",
    "\n",
    "        # Get the model prediction\n",
    "        pred = net(noisy_x, timesteps, y)  # Note that we pass in the labels y\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(pred, noise)  # How close is the output to the noise\n",
    "\n",
    "        # Backprop and update the params:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # Store the loss for later\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # Print out the average of the last 100 loss values to get an idea of progress:\n",
    "    avg_loss = sum(losses[-100:]) / 100\n",
    "    print(f\"Finished epoch {epoch}. Average of the last 100 loss values: {avg_loss:05f}\")\n",
    "\n",
    "# View the loss curve\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e862ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling one sample:\n",
    "\n",
    "# Prepare random x to start from, plus desired label y\n",
    "x = torch.randn(1, 1, 57, 57).to(device)\n",
    "y = torch.tensor([25]).to(device)  # Example class label (0-49)\n",
    "\n",
    "# Sampling loop\n",
    "for i, t in tqdm(enumerate(noise_scheduler.timesteps)):\n",
    "    with torch.no_grad():\n",
    "        residual = net(x, t, y)\n",
    "    x = noise_scheduler.step(residual, t, x).prev_sample\n",
    "\n",
    "# Show the result\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.imshow(x.detach().cpu().clip(-1, 1).squeeze(), cmap=\"Greys\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
