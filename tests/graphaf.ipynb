{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5481fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../polygraphpy/data/polarizability_data.csv')\n",
    "df = df[df['chain_size'] == 0]\n",
    "df.to_csv('filterd_polarizability.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0422cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgduarte/psi4conda/lib/python3.10/site-packages/torchdrug/data/feature.py:42: UserWarning: Unknown value `Na`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/home/jgduarte/psi4conda/lib/python3.10/site-packages/torchdrug/data/feature.py:42: UserWarning: Unknown value `K`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchdrug import data, models, tasks, core\n",
    "from torchdrug.layers import distribution\n",
    "from torchdrug.core import Registry as R\n",
    "from torch import nn, optim\n",
    "\n",
    "@R.register(\"datasets.CustomMolecule\")\n",
    "class CustomMoleculeDataset(data.MoleculeDataset):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "dataset = CustomMoleculeDataset()\n",
    "dataset.load_csv('filterd_polarizability.csv', smiles_field='smiles', target_fields=['static_polarizability'], kekulize=True, atom_feature='symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dafd22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:22:35   Preprocess training set\n",
      "16:22:35   {'batch_size': 32,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'capturable': False,\n",
      "               'class': 'optim.Adam',\n",
      "               'differentiable': False,\n",
      "               'eps': 1e-08,\n",
      "               'foreach': None,\n",
      "               'fused': None,\n",
      "               'lr': 0.001,\n",
      "               'maximize': False,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'agent_update_interval': 5,\n",
      "          'baseline_momentum': 0.9,\n",
      "          'class': 'tasks.AutoregressiveGeneration',\n",
      "          'criterion': 'nll',\n",
      "          'edge_model': {'class': 'models.GraphAF',\n",
      "                         'dequantization_noise': 0.9,\n",
      "                         'model': {'activation': 'relu',\n",
      "                                   'batch_norm': True,\n",
      "                                   'class': 'models.RGCN',\n",
      "                                   'concat_hidden': False,\n",
      "                                   'edge_input_dim': None,\n",
      "                                   'hidden_dims': [128, 128, 128],\n",
      "                                   'input_dim': 13,\n",
      "                                   'num_relation': 3,\n",
      "                                   'readout': 'sum',\n",
      "                                   'short_cut': False},\n",
      "                         'num_layer': 12,\n",
      "                         'num_mlp_layer': 2,\n",
      "                         'prior': IndependentGaussian(),\n",
      "                         'use_edge': True},\n",
      "          'gamma': 0.9,\n",
      "          'max_edge_unroll': 12,\n",
      "          'max_node': 38,\n",
      "          'node_model': {'class': 'models.GraphAF',\n",
      "                         'dequantization_noise': 0.9,\n",
      "                         'model': {'activation': 'relu',\n",
      "                                   'batch_norm': True,\n",
      "                                   'class': 'models.RGCN',\n",
      "                                   'concat_hidden': False,\n",
      "                                   'edge_input_dim': None,\n",
      "                                   'hidden_dims': [128, 128, 128],\n",
      "                                   'input_dim': 13,\n",
      "                                   'num_relation': 3,\n",
      "                                   'readout': 'sum',\n",
      "                                   'short_cut': False},\n",
      "                         'num_layer': 12,\n",
      "                         'num_mlp_layer': 2,\n",
      "                         'prior': IndependentGaussian(),\n",
      "                         'use_edge': False},\n",
      "          'num_edge_sample': -1,\n",
      "          'num_node_sample': -1,\n",
      "          'reward_temperature': 1,\n",
      "          'task': ()},\n",
      " 'test_set': None,\n",
      " 'train_set': {'class': 'datasets.CustomMolecule'},\n",
      " 'valid_set': None}\n"
     ]
    }
   ],
   "source": [
    "model = models.RGCN(input_dim=dataset.num_atom_type, num_relation=dataset.num_bond_type, hidden_dims=[128, 128, 128], batch_norm=True)\n",
    "\n",
    "num_atom_type = dataset.num_atom_type\n",
    "num_bond_type = dataset.num_bond_type + 1\n",
    "\n",
    "node_prior = distribution.IndependentGaussian(torch.zeros(num_atom_type), torch.ones(num_atom_type))\n",
    "edge_prior = distribution.IndependentGaussian(torch.zeros(num_bond_type), torch.ones(num_bond_type))\n",
    "\n",
    "node_flow = models.GraphAF(model, node_prior, num_layer=12)\n",
    "edge_flow = models.GraphAF(model, edge_prior, use_edge=True, num_layer=12)\n",
    "\n",
    "task = tasks.AutoregressiveGeneration(node_flow, edge_flow, max_node=38, max_edge_unroll=12, criterion='nll')\n",
    "\n",
    "optimizer = optim.Adam(task.parameters(), lr=1e-3)\n",
    "solver = core.Engine(task, dataset, None, None, optimizer, gpus=[0], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818024e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:22:37   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "16:22:37   Epoch 0 begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgduarte/psi4conda/lib/python3.10/site-packages/torchdrug/data/molecule.py:124: UserWarning: Try to apply masks on molecules with stereo bonds. This may produce invalid molecules. To discard stereo information, call `mol.bond_stereo[:] = 0` before applying masks.\n",
      "  warnings.warn(\"Try to apply masks on molecules with stereo bonds. This may produce invalid molecules. \"\n",
      "/home/jgduarte/psi4conda/lib/python3.10/site-packages/torchdrug/data/molecule.py:124: UserWarning: Try to apply masks on molecules with stereo bonds. This may produce invalid molecules. To discard stereo information, call `mol.bond_stereo[:] = 0` before applying masks.\n",
      "  warnings.warn(\"Try to apply masks on molecules with stereo bonds. This may produce invalid molecules. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:22:38   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "16:22:38   edge log likelihood: -24.3833\n",
      "16:22:38   edge mask / graph: 175.812\n",
      "16:22:38   node log likelihood: -3007.38\n",
      "16:22:38   node mask / graph: 21.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgduarte/psi4conda/lib/python3.10/site-packages/torchdrug/tasks/generation.py:505: UserWarning: Graphs with less than 2 nodes can't be used for edge generation learning. Dropped\n",
      "  warnings.warn(\"Graphs with less than 2 nodes can't be used for edge generation learning. Dropped\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:22:51   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "16:22:51   edge log likelihood: -3.77118\n",
      "16:22:51   edge mask / graph: 182.625\n",
      "16:22:51   node log likelihood: -15.2756\n",
      "16:22:51   node mask / graph: 21.7188\n",
      "16:23:03   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "16:23:03   edge log likelihood: -2.6299\n",
      "16:23:03   edge mask / graph: 204.375\n",
      "16:23:03   node log likelihood: -14.8928\n",
      "16:23:03   node mask / graph: 23.5312\n"
     ]
    }
   ],
   "source": [
    "solver.train(num_epoch=10)\n",
    "solver.save('graphaf_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509f7bc5",
   "metadata": {},
   "source": [
    "# New try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# PyG DataLoader and utils are no longer strictly needed for data loading,\n",
    "# but kept for completeness if other PyG utilities are used elsewhere.\n",
    "from torch_geometric.data import Data, DataLoader as PyGDataLoader\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import torchdrug components\n",
    "import torchdrug\n",
    "from torchdrug import core, models, tasks\n",
    "from torchdrug.data import Molecule\n",
    "from torchdrug.layers import distribution # Added for priors\n",
    "from torch.utils import data as torch_data # To avoid conflict with PyG DataLoader\n",
    "\n",
    "# Ensure deterministic behavior for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # --- 1. Load Data using TorchDrug's Molecule.load_csv ---\n",
    "    csv_file_path = '../polygraphpy/data/polarizability_data.csv'\n",
    "    \n",
    "    # Define target and feature fields for TorchDrug\n",
    "    # 'y' will be 'static_polarizability'\n",
    "    # 'chain_size', 'xx', 'yy', 'zz' will be loaded as additional features/attributes\n",
    "    target_fields = [\"static_polarizability\"]\n",
    "    feature_fields = [\"chain_size\", \"xx\", \"yy\", \"zz\"] # These will be accessible as mol.chain_size, mol.xx etc.\n",
    "\n",
    "    print(f\"Loading data from {csv_file_path} using TorchDrug...\")\n",
    "    # TorchDrug's Molecule.load_csv handles SMILES parsing and feature extraction\n",
    "    # It automatically infers atom types, bond types, and basic atom/bond features.\n",
    "    # Custom features specified in `feature_fields` are added as attributes to the Molecule object.\n",
    "    full_torchdrug_dataset = Molecule.load_csv(\n",
    "        csv_file_path,\n",
    "        smiles_field=\"smiles\",\n",
    "        target_fields=target_fields,\n",
    "        feature_fields=feature_fields,\n",
    "        verbose=1 # Show progress\n",
    "    )\n",
    "    print(f\"Loaded {len(full_torchdrug_dataset)} molecules from CSV.\")\n",
    "\n",
    "    # --- 2. Filter data for chain_size == 0 ---\n",
    "    print(\"Filtering data for chain_size == 0...\")\n",
    "    filtered_torchdrug_dataset = []\n",
    "    for mol in tqdm(full_torchdrug_dataset, desc=\"Filtering molecules\"):\n",
    "        # Access chain_size. It's loaded as a tensor, so use .item()\n",
    "        if hasattr(mol, 'chain_size') and mol.chain_size.item() == 0:\n",
    "            filtered_torchdrug_dataset.append(mol)\n",
    "    \n",
    "    # Create a new MoleculeDataset from the filtered list\n",
    "    # This is important for TorchDrug's internal indexing and properties.\n",
    "    training_dataset_torchdrug = torchdrug.data.MoleculeDataset(filtered_torchdrug_dataset)\n",
    "\n",
    "    print(f\"Filtered down to {len(training_dataset_torchdrug)} molecules with chain_size == 0.\")\n",
    "    \n",
    "    if not training_dataset_torchdrug:\n",
    "        print(\"Error: No molecules found after filtering. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # --- 3. Determine dimensions for GraphAF from the filtered dataset ---\n",
    "    # TorchDrug datasets have properties to infer these directly\n",
    "    NUM_ATOM_TYPES = training_dataset_torchdrug.num_atom_types\n",
    "    NUM_BOND_TYPES = training_dataset_torchdrug.num_bond_types\n",
    "    \n",
    "    # atom_feature_dim and bond_feature_dim in GraphAF refer to *additional* features\n",
    "    # beyond the standard atom/bond types that TorchDrug automatically encodes.\n",
    "    # For RGCN, input_dim is num_atom_type and num_relation is num_bond_type.\n",
    "    # GraphAF then uses the RGCN output.\n",
    "    # So, ATOM_FEATURE_DIM and BOND_FEATURE_DIM from the dataset are not directly used\n",
    "    # in the RGCN initialization for input/relation dimensions, but rather for the\n",
    "    # overall context of the dataset.\n",
    "    MAX_NODES_IN_DATASET = max([mol.num_atom for mol in training_dataset_torchdrug]) if training_dataset_torchdrug else 0\n",
    "\n",
    "    print(f\"Inferred Num Atom Types: {NUM_ATOM_TYPES}\")\n",
    "    print(f\"Inferred Num Bond Types: {NUM_BOND_TYPES}\")\n",
    "    # Note: TorchDrug's MoleculeDataset.atom_feature_dim and bond_feature_dim\n",
    "    # refer to the dimensions of the *default* features (e.g., atomic number, degree, etc.)\n",
    "    # that TorchDrug automatically extracts, not necessarily the input_dim for RGCN\n",
    "    # which typically takes atom_type indices.\n",
    "    print(f\"Max Nodes in Filtered Dataset: {MAX_NODES_IN_DATASET}\")\n",
    "\n",
    "    # Create TorchDrug DataLoader\n",
    "    torchdrug_data_loader = torch_data.DataLoader(\n",
    "        training_dataset_torchdrug, batch_size=32, shuffle=True, collate_fn=training_dataset_torchdrug.collate_fn\n",
    "    )\n",
    "\n",
    "    # --- 4. Initialize GraphAF Model Components ---\n",
    "    # As per the tutorial: RGCN as the underlying GNN, then GraphAF flows.\n",
    "    \n",
    "    # Define the underlying GNN model (RGCN)\n",
    "    # input_dim for RGCN is the number of atom types for one-hot encoding\n",
    "    # num_relation for RGCN is the number of bond types\n",
    "    rgcn_model = models.RGCN(input_dim=NUM_ATOM_TYPES,\n",
    "                             num_relation=NUM_BOND_TYPES,\n",
    "                             hidden_dims=[256, 256, 256],\n",
    "                             batch_norm=True).to(device)\n",
    "\n",
    "    # Define node and edge priors\n",
    "    # num_atom_type is for node features (atom types)\n",
    "    node_prior = distribution.IndependentGaussian(torch.zeros(NUM_ATOM_TYPES, device=device),\n",
    "                                                  torch.ones(NUM_ATOM_TYPES, device=device))\n",
    "    # num_bond_type + 1 for edge features (bond types + non-edge)\n",
    "    edge_prior = distribution.IndependentGaussian(torch.zeros(NUM_BOND_TYPES + 1, device=device),\n",
    "                                                  torch.ones(NUM_BOND_TYPES + 1, device=device))\n",
    "\n",
    "    # Define GraphAF flows\n",
    "    # The `model` argument here is the RGCN instance\n",
    "    node_flow = models.GraphAF(rgcn_model, node_prior, num_layer=12).to(device)\n",
    "    edge_flow = models.GraphAF(rgcn_model, edge_prior, use_edge=True, num_layer=12).to(device)\n",
    "\n",
    "    # --- 5. Define Training Task and Engine (Unconditional Generation) ---\n",
    "    print(\"\\n--- Unconditional Graph Generation Training ---\")\n",
    "    unconditional_task = tasks.AutoregressiveGeneration(node_flow, edge_flow,\n",
    "                                                        max_node=MAX_NODES_IN_DATASET,\n",
    "                                                        max_edge_unroll=12, # From tutorial\n",
    "                                                        criterion=\"nll\") # Negative Log Likelihood\n",
    "\n",
    "    unconditional_optimizer = torch.optim.Adam(unconditional_task.parameters(), lr=1e-3)\n",
    "    unconditional_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(unconditional_optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "    unconditional_solver = core.Engine(unconditional_task, training_dataset_torchdrug, # Use the dataset directly\n",
    "                                        unconditional_optimizer, unconditional_scheduler,\n",
    "                                        device=device, batch_size=32, log_interval=10)\n",
    "\n",
    "    # --- 6. Train the Model (Unconditional) ---\n",
    "    print(\"\\nStarting GraphAF unconditional training...\")\n",
    "    unconditional_solver.train(num_epoch=10) # Train for 10 epochs (adjust as needed)\n",
    "    print(\"GraphAF unconditional training complete.\")\n",
    "\n",
    "    # --- Save the unconditionally trained model ---\n",
    "    unconditional_model_path = \"graphaf_monomer_unconditional.pkl\"\n",
    "    unconditional_solver.save(unconditional_model_path)\n",
    "    print(f\"Unconditional model saved to {unconditional_model_path}\")\n",
    "\n",
    "    # --- 7. Property-Guided Fine-tuning (Reinforcement Learning) ---\n",
    "    print(\"\\n--- Property-Guided Fine-tuning (Reinforcement Learning) ---\")\n",
    "    # Define a new task for RL fine-tuning\n",
    "    # Use your target property: \"static_polarizability\"\n",
    "    rl_task = tasks.AutoregressiveGeneration(node_flow, edge_flow,\n",
    "                                            max_node=MAX_NODES_IN_DATASET,\n",
    "                                            max_edge_unroll=12,\n",
    "                                            task=\"static_polarizability\", # Your target property\n",
    "                                            criterion={\"ppo\": 0.25, \"nll\": 1.0}, # PPO for RL, NLL for validity\n",
    "                                            reward_temperature=20, # From tutorial\n",
    "                                            baseline_momentum=0.9, # From tutorial\n",
    "                                            agent_update_interval=5, # From tutorial\n",
    "                                            gamma=0.9) # From tutorial\n",
    "\n",
    "    rl_optimizer = torch.optim.Adam(rl_task.parameters(), lr=1e-5) # Smaller LR for fine-tuning\n",
    "    rl_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(rl_optimizer, mode='max', factor=0.5, patience=5,\n",
    "                                                               metric=\"static_polarizability/mean\") # Monitor property for RL\n",
    "\n",
    "    rl_solver = core.Engine(rl_task, training_dataset_torchdrug, # Use the dataset directly\n",
    "                            rl_optimizer, rl_scheduler,\n",
    "                            device=device, batch_size=32, log_interval=10)\n",
    "\n",
    "    # Load the unconditionally trained model for fine-tuning\n",
    "    print(f\"Loading unconditional model from {unconditional_model_path} for fine-tuning...\")\n",
    "    rl_solver.load(unconditional_model_path, load_optimizer=False) # Load model weights, not optimizer state\n",
    "\n",
    "    # --- 8. Train the Model (RL Fine-tuning) ---\n",
    "    print(\"\\nStarting GraphAF RL fine-tuning...\")\n",
    "    rl_solver.train(num_epoch=10) # Train for 10 epochs (adjust as needed)\n",
    "    print(\"GraphAF RL fine-tuning complete.\")\n",
    "\n",
    "    # --- Save the fine-tuned model ---\n",
    "    finetuned_model_path = \"graphaf_monomer_finetuned.pkl\"\n",
    "    rl_solver.save(finetuned_model_path)\n",
    "    print(f\"Fine-tuned model saved to {finetuned_model_path}\")\n",
    "\n",
    "\n",
    "    # --- 9. Generate New Graphs ---\n",
    "    print(\"\\nGenerating new graphs with the fine-tuned GraphAF model...\")\n",
    "    num_graphs_to_generate = 5\n",
    "\n",
    "    # When generating after RL fine-tuning, the model is biased to produce\n",
    "    # molecules with higher (or lower, depending on reward) values of the target property.\n",
    "    # The `generate` method itself is still unconditional in terms of direct property input.\n",
    "    \n",
    "    # Generate molecules. The `generate` method returns a list of Molecule objects.\n",
    "    generated_molecules = rgcn_model.generate(node_flow, edge_flow, num_graphs_to_generate,\n",
    "                                               max_num_nodes=MAX_NODES_IN_DATASET)\n",
    "\n",
    "    print(f\"Generated {len(generated_molecules)} molecules.\")\n",
    "    for i, mol in enumerate(generated_molecules):\n",
    "        print(f\"\\nGenerated Molecule {i+1}:\")\n",
    "        print(f\"  Number of atoms: {mol.num_atom}\")\n",
    "        print(f\"  Number of bonds: {mol.num_bond}\")\n",
    "        # You can inspect the atom types and bond types\n",
    "        # print(f\"  Atom types: {mol.atom_type.tolist()}\")\n",
    "        # print(f\"  Bond types: {mol.bond_type.tolist()}\")\n",
    "        # print(f\"  Bond index: {mol.bond_index.tolist()}\")\n",
    "        \n",
    "        # To visualize or further process, you'd typically convert these\n",
    "        # torchdrug.data.Molecule objects to RDKit molecules.\n",
    "        # This requires RDKit and appropriate atom/bond type mapping.\n",
    "        # Example (requires RDKit and appropriate atom/bond type mapping):\n",
    "        # from rdkit import Chem\n",
    "        # from rdkit.Chem.rdchem import BondType\n",
    "        # # Define your atom and bond mappings based on your dataset's chemistry\n",
    "        # # Example: atom_map = {0: Chem.Atom(\"C\"), 1: Chem.Atom(\"O\"), ...}\n",
    "        # # bond_map = {0: BondType.SINGLE, 1: BondType.DOUBLE, ...}\n",
    "        #\n",
    "        # try:\n",
    "        #     rdkit_mol = Chem.Mol()\n",
    "        #     editable_mol = Chem.RWMol(rdkit_mol)\n",
    "        #     for atom_idx in range(mol.num_atom):\n",
    "        #         atom_type_idx = mol.atom_type[atom_idx].item()\n",
    "        #         # Add atom based on atom_type_idx and your mapping\n",
    "        #         # editable_mol.AddAtom(atom_map.get(atom_type_idx, Chem.Atom(\"C\")))\n",
    "        #         # For now, just add a generic atom if no mapping is provided\n",
    "        #         editable_mol.AddAtom(Chem.Atom(str(atom_type_idx))) # Convert to string for generic atom\n",
    "        #\n",
    "        #     for bond_idx in range(mol.num_bond):\n",
    "        #         src, dst = mol.bond_index[:, bond_idx].tolist()\n",
    "        #         bond_type_idx = mol.bond_type[bond_idx].item()\n",
    "        #         # Add bond based on bond_type_idx and your mapping\n",
    "        #         # editable_mol.AddBond(src, dst, bond_map.get(bond_type_idx, BondType.SINGLE))\n",
    "        #         # For now, just add a generic single bond\n",
    "        #         editable_mol.AddBond(src, dst)\n",
    "        #\n",
    "        #     rdkit_mol = editable_mol.GetMol()\n",
    "        #     print(f\"  RDKit SMILES: {Chem.MolToSmiles(rdkit_mol)}\")\n",
    "        # except Exception as e:\n",
    "        #     print(f\"  Error converting to RDKit molecule: {e}\")\n",
    "        #     print(\"  (RDKit conversion requires careful mapping of atom/bond types and RDKit installation)\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
