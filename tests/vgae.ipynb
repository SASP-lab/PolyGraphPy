{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390c82db",
   "metadata": {},
   "source": [
    "# GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c9b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26582it [00:09, 2831.03it/s]\n",
      "/Users/gabriel/Documents/Apps/PolyGraphPy/.venv/lib/python3.13/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Feature Dimension: 75\n",
      "Max Nodes in Dataset: 176\n",
      "Number of graphs loaded: 25266\n",
      "Starting training...\n",
      "Epoch 1/50, Loss: 8080.3697\n",
      "Epoch 2/50, Loss: 6926.6681\n",
      "Epoch 3/50, Loss: 6456.2448\n",
      "Epoch 4/50, Loss: 6097.8192\n",
      "Epoch 5/50, Loss: 5945.1236\n",
      "Epoch 6/50, Loss: 5844.3312\n",
      "Epoch 7/50, Loss: 5772.5932\n",
      "Epoch 8/50, Loss: 5720.5624\n",
      "Epoch 9/50, Loss: 5683.5963\n",
      "Epoch 10/50, Loss: 5649.1427\n",
      "Epoch 11/50, Loss: 5627.9458\n",
      "Epoch 12/50, Loss: 5590.3034\n",
      "Epoch 13/50, Loss: 5520.1587\n",
      "Epoch 14/50, Loss: 5457.9590\n",
      "Epoch 15/50, Loss: 5395.3282\n",
      "Epoch 16/50, Loss: 5341.6473\n",
      "Epoch 17/50, Loss: 5292.2387\n",
      "Epoch 18/50, Loss: 5257.0820\n",
      "Epoch 19/50, Loss: 5214.3655\n",
      "Epoch 20/50, Loss: 5181.1885\n",
      "Epoch 21/50, Loss: 5171.2739\n",
      "Epoch 22/50, Loss: 5139.5923\n",
      "Epoch 23/50, Loss: 5124.6393\n",
      "Epoch 24/50, Loss: 5112.2911\n",
      "Epoch 25/50, Loss: 5093.7530\n",
      "Epoch 26/50, Loss: 5078.1278\n",
      "Epoch 27/50, Loss: 5066.2429\n",
      "Epoch 28/50, Loss: 5039.6674\n",
      "Epoch 29/50, Loss: 5036.2573\n",
      "Epoch 30/50, Loss: 5020.7565\n",
      "Epoch 31/50, Loss: 5017.3922\n",
      "Epoch 32/50, Loss: 4997.1220\n",
      "Epoch 33/50, Loss: 4991.8845\n",
      "Epoch 34/50, Loss: 4971.9346\n",
      "Epoch 35/50, Loss: 4971.9995\n",
      "Epoch 36/50, Loss: 4959.2734\n",
      "Epoch 37/50, Loss: 4947.6802\n",
      "Epoch 38/50, Loss: 4941.5243\n",
      "Epoch 39/50, Loss: 4923.4951\n",
      "Epoch 40/50, Loss: 4912.8791\n",
      "Epoch 41/50, Loss: 4895.4535\n",
      "Epoch 42/50, Loss: 4876.6556\n",
      "Epoch 43/50, Loss: 4870.1615\n",
      "Epoch 44/50, Loss: 4862.9585\n",
      "Epoch 45/50, Loss: 4847.1591\n",
      "Epoch 46/50, Loss: 4836.2304\n",
      "Epoch 47/50, Loss: 4829.8242\n",
      "Epoch 48/50, Loss: 4815.2256\n",
      "Epoch 49/50, Loss: 4812.7409\n",
      "Epoch 50/50, Loss: 4806.9013\n",
      "Training complete.\n",
      "\n",
      "Generating new graphs...\n",
      "Generated 5 graphs.\n",
      "\n",
      "Generated Graph 1 (Target Property: 50.0):\n",
      "  Shape: torch.Size([176, 176])\n",
      "  Adjacency Matrix (top 5x5):\n",
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "\n",
      "Generated Graph 2 (Target Property: 75.0):\n",
      "  Shape: torch.Size([176, 176])\n",
      "  Adjacency Matrix (top 5x5):\n",
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "\n",
      "Generated Graph 3 (Target Property: 100.0):\n",
      "  Shape: torch.Size([176, 176])\n",
      "  Adjacency Matrix (top 5x5):\n",
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "\n",
      "Generated Graph 4 (Target Property: 125.0):\n",
      "  Shape: torch.Size([176, 176])\n",
      "  Adjacency Matrix (top 5x5):\n",
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 0.]])\n",
      "\n",
      "Generated Graph 5 (Target Property: 150.0):\n",
      "  Shape: torch.Size([176, 176])\n",
      "  Adjacency Matrix (top 5x5):\n",
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import to_dense_adj, dense_to_sparse\n",
    "import pandas as pd # Added for data loading\n",
    "from tqdm import tqdm # Added for progress bar\n",
    "\n",
    "# Ensure deterministic behavior for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# --- 1. Define the Conditional Graph VAE Model ---\n",
    "# Using ConditionalGraphVAE_Updated as the primary model class.\n",
    "\n",
    "class ConditionalGraphVAE_Updated(nn.Module):\n",
    "    def __init__(self, node_feature_dim, property_dim, hidden_dim, latent_dim, max_nodes_for_decode):\n",
    "        \"\"\"\n",
    "        Initializes the Conditional Graph Variational Autoencoder.\n",
    "\n",
    "        Args:\n",
    "            node_feature_dim (int): Dimension of input node features.\n",
    "            property_dim (int): Dimension of the property vector.\n",
    "            hidden_dim (int): Dimension of the hidden layers in GNNs.\n",
    "            latent_dim (int): Dimension of the latent space.\n",
    "            max_nodes_for_decode (int): Maximum number of nodes the decoder can generate/reconstruct for.\n",
    "        \"\"\"\n",
    "        super(ConditionalGraphVAE_Updated, self).__init__()\n",
    "\n",
    "        self.node_feature_dim = node_feature_dim\n",
    "        self.property_dim = property_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.max_nodes_for_decode = max_nodes_for_decode # Store this for the decoder\n",
    "\n",
    "        # --- Encoder ---\n",
    "        # The encoder takes node features (x) and the property (y)\n",
    "        # We concatenate the property to each node's feature vector.\n",
    "        # This allows the GNN to learn property-aware node representations.\n",
    "        self.encoder_conv1 = GCNConv(node_feature_dim + property_dim, hidden_dim)\n",
    "        self.encoder_conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Output layers for mean and log-variance of the latent distribution\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # --- Decoder ---\n",
    "        # The decoder takes a latent vector (z) and the property (y)\n",
    "        # It aims to reconstruct the adjacency matrix.\n",
    "        # We concatenate the property to the latent vector.\n",
    "        self.decoder_fc1 = nn.Linear(latent_dim + property_dim, hidden_dim)\n",
    "        self.decoder_fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Final layer to predict flattened adjacency matrix\n",
    "        # The output size is fixed based on the maximum number of nodes in the dataset.\n",
    "        self.decoder_fc_adj = nn.Linear(hidden_dim, max_nodes_for_decode * max_nodes_for_decode)\n",
    "\n",
    "    def encode(self, x, edge_index, batch, y):\n",
    "        \"\"\"\n",
    "        Encodes the input graph and property into a latent distribution.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Node feature matrix.\n",
    "            edge_index (torch.Tensor): Graph connectivity.\n",
    "            batch (torch.Tensor): Batch vector, mapping each node to its respective graph in the batch.\n",
    "            y (torch.Tensor): Property vector for each graph in the batch.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (mu, logvar) - mean and log-variance of the latent distribution.\n",
    "        \"\"\"\n",
    "        # Expand property 'y' to match the number of nodes in each graph\n",
    "        # Fix: Unsqueeze expanded_y to have 2 dimensions for concatenation\n",
    "        expanded_y = y[batch].unsqueeze(-1) # This correctly maps batch index to property and adds a dimension\n",
    "\n",
    "        # Concatenate node features with the property vector\n",
    "        x_with_prop = torch.cat([x, expanded_y], dim=-1)\n",
    "\n",
    "        x_with_prop = self.encoder_conv1(x_with_prop, edge_index)\n",
    "        x_with_prop = F.relu(x_with_prop)\n",
    "        x_with_prop = self.encoder_conv2(x_with_prop, edge_index)\n",
    "        x_with_prop = F.relu(x_with_prop)\n",
    "\n",
    "        # Global pooling to get a graph-level representation\n",
    "        graph_embedding = global_mean_pool(x_with_prop, batch)\n",
    "\n",
    "        mu = self.fc_mu(graph_embedding)\n",
    "        logvar = self.fc_logvar(graph_embedding)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Performs the reparameterization trick to sample from the latent distribution.\n",
    "\n",
    "        Args:\n",
    "            mu (torch.Tensor): Mean of the latent distribution.\n",
    "            logvar (torch.Tensor): Log-variance of the latent distribution.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Sampled latent vector.\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, y, num_nodes_per_graph):\n",
    "        \"\"\"\n",
    "        Decodes a latent vector and property back into an adjacency matrix.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Latent vector.\n",
    "            y (torch.Tensor): Property vector.\n",
    "            num_nodes_per_graph (list): List of number of nodes for each graph in the batch.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of reconstructed dense adjacency matrices.\n",
    "        \"\"\"\n",
    "        # Fix: Unsqueeze y to have 2 dimensions for concatenation with z\n",
    "        # z is [batch_size, latent_dim] (2D)\n",
    "        # y is [batch_size] (1D) from DataLoader if individual y is [1]\n",
    "        # We need y to be [batch_size, 1] to concatenate with z\n",
    "        y_reshaped = y.unsqueeze(-1)\n",
    "\n",
    "        # Concatenate latent vector with property\n",
    "        z_with_prop = torch.cat([z, y_reshaped], dim=-1)\n",
    "\n",
    "        # Transform the combined latent vector\n",
    "        h = F.relu(self.decoder_fc1(z_with_prop))\n",
    "        h = F.relu(self.decoder_fc2(h))\n",
    "\n",
    "        # Project `h` to a flattened adjacency matrix for `self.max_nodes_for_decode`\n",
    "        adj_flat = self.decoder_fc_adj(h)\n",
    "        adj_reconstructed = adj_flat.view(-1, self.max_nodes_for_decode, self.max_nodes_for_decode)\n",
    "        adj_reconstructed = torch.sigmoid(adj_reconstructed) # Sigmoid for probabilities\n",
    "\n",
    "        # Now, mask the reconstructed adjacency matrix to the actual number of nodes for each graph.\n",
    "        masked_adj_list = []\n",
    "        for i, num_nodes in enumerate(num_nodes_per_graph):\n",
    "            # Take the relevant part of the reconstructed matrix\n",
    "            current_adj = adj_reconstructed[i, :num_nodes, :num_nodes]\n",
    "            masked_adj_list.append(current_adj)\n",
    "        return masked_adj_list # Return as a list of dense adjacency matrices\n",
    "\n",
    "    def forward(self, x, edge_index, batch, y, num_nodes_per_graph):\n",
    "        \"\"\"\n",
    "        Forward pass of the C-GVAE.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Node feature matrix.\n",
    "            edge_index (torch.Tensor): Graph connectivity.\n",
    "            batch (torch.Tensor): Batch vector.\n",
    "            y (torch.Tensor): Property vector.\n",
    "            num_nodes_per_graph (list): List of number of nodes for each graph in the batch.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (reconstructed_adj_list, mu, logvar)\n",
    "        \"\"\"\n",
    "        mu, logvar = self.encode(x, edge_index, batch, y)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconstructed_adj_list = self.decode(z, y, num_nodes_per_graph)\n",
    "        return reconstructed_adj_list, mu, logvar\n",
    "\n",
    "    def generate(self, num_samples, target_properties):\n",
    "        \"\"\"\n",
    "        Generates new graphs conditioned on target properties.\n",
    "\n",
    "        Args:\n",
    "            num_samples (int): Number of graphs to generate.\n",
    "            target_properties (torch.Tensor): Tensor of target properties,\n",
    "                                             shape `[num_samples, property_dim]`.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of generated dense adjacency matrices.\n",
    "        \"\"\"\n",
    "        if target_properties.shape[0] != num_samples:\n",
    "            raise ValueError(\"Number of samples must match the number of target properties.\")\n",
    "\n",
    "        # Sample from a standard normal distribution for the latent space\n",
    "        z = torch.randn(num_samples, self.latent_dim).to(target_properties.device)\n",
    "\n",
    "        # Concatenate latent vector with property\n",
    "        # Ensure target_properties is 2D, e.g., [num_samples, 1]\n",
    "        z_with_prop = torch.cat([z, target_properties], dim=-1)\n",
    "\n",
    "        # Transform the combined latent vector\n",
    "        h = F.relu(self.decoder_fc1(z_with_prop))\n",
    "        h = F.relu(self.decoder_fc2(h))\n",
    "\n",
    "        # Project `h` to a flattened adjacency matrix for `self.max_nodes_for_decode`\n",
    "        adj_flat = self.decoder_fc_adj(h)\n",
    "        adj_generated = adj_flat.view(-1, self.max_nodes_for_decode, self.max_nodes_for_decode)\n",
    "        adj_generated = torch.sigmoid(adj_generated) # Probabilities\n",
    "\n",
    "        # Threshold to get binary adjacency matrix\n",
    "        generated_graphs = (adj_generated > 0.5).float() # Simple thresholding\n",
    "\n",
    "        return [graph for graph in generated_graphs] # Return as a list of dense matrices\n",
    "\n",
    "\n",
    "# --- 2. Define the Loss Function ---\n",
    "\n",
    "def vae_loss(reconstructed_adj_list, original_adj_list, mu, logvar):\n",
    "    \"\"\"\n",
    "    Calculates the VAE loss, consisting of reconstruction loss and KL divergence.\n",
    "\n",
    "    Args:\n",
    "        reconstructed_adj_list (list): List of reconstructed dense adjacency matrices.\n",
    "        original_adj_list (list): List of original dense adjacency matrices.\n",
    "        mu (torch.Tensor): Mean of the latent distribution.\n",
    "        logvar (torch.Tensor): Log-variance of the latent distribution.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Total VAE loss.\n",
    "    \"\"\"\n",
    "    reconstruction_loss = 0\n",
    "    for recon_adj, orig_adj in zip(reconstructed_adj_list, original_adj_list):\n",
    "        # Binary Cross-Entropy for adjacency matrix reconstruction\n",
    "        reconstruction_loss += F.binary_cross_entropy(recon_adj, orig_adj, reduction='sum')\n",
    "\n",
    "    # KL Divergence: D_KL(N(mu, sigma^2) || N(0, 1))\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # Beta-VAE often uses a beta parameter for KL divergence weight.\n",
    "    # For simplicity, we'll use beta=1 here.\n",
    "    total_loss = reconstruction_loss + kl_divergence\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# --- 3. Data Reading Function ---\n",
    "\n",
    "def read_train_data(data: pd.DataFrame):\n",
    "    training_dataset = []\n",
    "\n",
    "    print(f'Reading training data.')\n",
    "    for row in tqdm(data.itertuples()):\n",
    "        try:\n",
    "            # Assuming .pt files contain torch_geometric.data.Data objects\n",
    "            training_dataset.append(torch.load(f'../polygraphpy/data/training_input_data/{row.id}_{row.chain_size}.pt', weights_only=False))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    # Determine input_dim from the first loaded graph's node features\n",
    "    input_dim : int = training_dataset[0].x.shape[1] if training_dataset else 0\n",
    "\n",
    "    return training_dataset, input_dim\n",
    "    \n",
    "# --- 4. Training Loop ---\n",
    "\n",
    "def train_c_gvae(model, data_loader, optimizer, epochs, device):\n",
    "    \"\"\"\n",
    "    Trains the Conditional Graph VAE model.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data in data_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Convert the batched `data` object back to a list of individual `Data` objects\n",
    "            # to easily get per-graph adjacency and num_nodes.\n",
    "            batch_data_list = data.to_data_list()\n",
    "            original_adj_list = []\n",
    "            num_nodes_per_graph = []\n",
    "            for single_graph_data in batch_data_list:\n",
    "                # Get dense adjacency for the current graph\n",
    "                adj = to_dense_adj(single_graph_data.edge_index, max_num_nodes=single_graph_data.num_nodes)[0]\n",
    "                original_adj_list.append(adj)\n",
    "                num_nodes_per_graph.append(single_graph_data.num_nodes)\n",
    "\n",
    "            reconstructed_adj_list, mu, logvar = model(\n",
    "                data.x, data.edge_index, data.batch, data.y, num_nodes_per_graph\n",
    "            )\n",
    "\n",
    "            loss = vae_loss(reconstructed_adj_list, original_adj_list, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(data_loader):.4f}\")\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load your actual data\n",
    "    df = pd.read_csv('../polygraphpy/data/polarizability_data.csv')\n",
    "    training_dataset, NODE_FEATURE_DIM = read_train_data(df)\n",
    "\n",
    "    # Determine MAX_NODES_IN_DATASET from your loaded data\n",
    "    MAX_NODES_IN_DATASET = 0\n",
    "    if training_dataset:\n",
    "        MAX_NODES_IN_DATASET = max([data.num_nodes for data in training_dataset])\n",
    "    else:\n",
    "        print(\"Warning: No training data loaded. Cannot determine MAX_NODES_IN_DATASET.\")\n",
    "        # Set a default or raise an error if no data is crucial\n",
    "        MAX_NODES_IN_DATASET = 20 # Fallback value if no data is loaded\n",
    "\n",
    "    # Hyperparameters\n",
    "    # NODE_FEATURE_DIM is now determined from your data\n",
    "    PROPERTY_DIM = 1      # Example: 1 for a scalar property like polarizability\n",
    "    HIDDEN_DIM = 64\n",
    "    LATENT_DIM = 32\n",
    "    # MAX_NODES_IN_DATASET is now determined from your data\n",
    "\n",
    "    print(f\"Node Feature Dimension: {NODE_FEATURE_DIM}\")\n",
    "    print(f\"Max Nodes in Dataset: {MAX_NODES_IN_DATASET}\")\n",
    "    print(f\"Number of graphs loaded: {len(training_dataset)}\")\n",
    "\n",
    "    # Create DataLoader\n",
    "    data_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Initialize model, optimizer\n",
    "    model = ConditionalGraphVAE_Updated(\n",
    "        NODE_FEATURE_DIM, PROPERTY_DIM, HIDDEN_DIM, LATENT_DIM, MAX_NODES_IN_DATASET\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    train_c_gvae(model, data_loader, optimizer, epochs=50, device=device)\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e399a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[7000].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f1d810f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Graph 1 (Target Property: 0.5):\n",
      "  Shape: torch.Size([176, 176])\n",
      "  Adjacency Matrix (top 5x5):\n",
      "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "num_graphs_to_generate = 1\n",
    "target_properties_for_gen = torch.tensor(\n",
    "    [[0.5241]], dtype=torch.float\n",
    ").to(device)\n",
    "\n",
    "generated_adj_matrices = model.generate(\n",
    "    num_graphs_to_generate,\n",
    "    target_properties_for_gen\n",
    ")\n",
    "\n",
    "for i, adj in enumerate(generated_adj_matrices):\n",
    "        print(f\"\\nGenerated Graph {i+1} (Target Property: {target_properties_for_gen[i].item():.1f}):\")\n",
    "        print(f\"  Shape: {adj.shape}\")\n",
    "        # Print a small part of the adjacency matrix for inspection\n",
    "        print(\"  Adjacency Matrix (top 5x5):\")\n",
    "        print(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee7ea3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "pred = adj.numpy()[:63,:63]\n",
    "y = to_dense_adj(training_dataset[7000].edge_index).numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "85e8c60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], shape=(63, 75), dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[7000].x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae8c608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      3839\n",
      "         1.0       0.59      0.35      0.44       130\n",
      "\n",
      "    accuracy                           0.97      3969\n",
      "   macro avg       0.78      0.67      0.71      3969\n",
      "weighted avg       0.97      0.97      0.97      3969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y.flatten(),pred.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0a80860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6727553249043221"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y.flatten(),pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c818d95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# First subplot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(y,)\n",
    "\n",
    "# Second subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(training_dataset[7000].x.numpy(),)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
